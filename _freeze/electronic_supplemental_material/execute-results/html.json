{
  "hash": "ee742989718e5dc2ece0aef9053a1267",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Electronic Supplemental Material: New Insights into PCA + Varimax for Psychological Researchers\"\nsubtitle: \"A short commentary on Rohe & Zeng (2023)\"\nauthor:\n  - name: Florian Pargent\n    affiliation: LMU Munich\n  - name: David Goretzko\n    affiliation: Utrecht University\n  - name: Timo von Oertzen\n    affiliation: Bundeswehr University Munich and Max Planck Institute for Human Development\ndate: last-modified\nbibliography: references.bib\ncsl: apa.csl\n---\n\n\n:::{.callout-important}\nThis document is **an updated copy** of a [published commentary](https://doi.org/10.1093/jrsssb/qkad054), to showcase [Quarto manuscripts](https://quarto.org/docs/manuscripts/) in our [Quarto workshop](https://florianpargent.github.io/Quarto_LMU_OSC/). The official online repository of our published commentary can be found [here](https://osf.io/5symf/).\n:::\n\n# A Short Commentary on Rohe & Zeng (2023)\n\nIn their paper *“Vintage factor analysis with varimax performs statistical inference”*, Rohe and Zeng [R&Z; @rohe2023vintage] demonstrate the usefulness of principal component analysis with varimax rotation (PCA+VR), a combination they call *vintage factor analysis*. The authors show that PCA+VR can be used to estimate factor scores and factor loadings, if a certain leptokurtic condition is fulfilled that can be assessed by simple visual diagnostics. In a side result, they also imply that PCA+VR is able to estimate factor scores even if the latent factors are correlated. In our commentary *\"New Insights into PCA + Varimax for Psychological Researchers\"* [@pargent2023discussion], we briefly discuss some implications of these results for psychological research and note that the suggested diagnostics of “radial streaks” might give less clear results in typical psychological applications. The commentary includes extensive *electronic supplemental materials*, containing a data example and a small simulation on estimating correlated factors, that can be found at <https://osf.io/5symf/>.\n\nIn the current electronic supplementary materials, we present i) an exemplary data analysis that is discussed in our comment, and ii) a small simulation demonstrating the ability of PCA+VR to estimate correlated factors.\n\n# Data Example: The PhoneStudy\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\nlibrary(knitr)\nlibrary(vsp)\nlibrary(Matrix)\nlibrary(scales)\n```\n:::\n\n\nIn contrast to the examples in R&Z which only deal with sparse binary network data, psychological applications (traditionally) deal with i) questionnaire items or (increasingly) ii) digital data, e.g., mobile sensing. The $A$ matrix consists of i) integer-valued responses on $d$ Likert items or ii) continuous values on $d$ sensing variables, by $n$ persons. Degree normalization discussed by R&Z does not seem suitable here and z-standardization is often required to detect meaningful factors in practice. We also do not share R&Z’s enthusiasm that \"radial streaks\" are common.\n\nFor the following demonstration, we use the publicly available *PhoneStudy* behavioral patterns dataset, which has been used to predict human personality from smartphone usage data [@stachl2020predicting]. The *PhoneStudy* collected i) self-reported questionnaire data of personality traits measured with the German Big Five Structure Inventory [BFSI; 5 factors and 30 facets, @arendasy_manual_2011], ii) demographic variables (age, gender, education), and iii) behavioral data from smartphone sensing (e.g., communication & social behavior, app-usage, music consumption, overall phone usage, day-nighttime activity), bundled from several smaller studies. The mobile sensing data was recorded for up to 30 days on the personal smartphone of study volunteers.\n\nItem responses to the personality questionnaire are contained in the file *datasets/Items.csv* while aggregated smartphone sensing variables are contained in the file *datasets/clusterdata.RDS*. Both can be downloaded from <https://osf.io/fxv3k/download>. We include copies of the aggregated datasets in our project repository for convenience. More details on the *PhoneStudy* data can be found in @stachl2020predicting. Mobile sensing variables are described in more detail at <https://compstat-lmu.shinyapps.io/Personality_Prediction/#section-datadict>.\n\n## Item Response Data\n\nItem responses to the 300 personality items of the Big Five questionnaire are almost complete and we decided to use complete case analysis here, although imputation would be possible as well.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\nphonedata_items = read.csv2(\"datasets/Items.csv\")\nphonedata_items = na.omit(phonedata_items[, 3:302])\n```\n:::\n\n\nAs is common for psychometric analyses, we standardize the item response data with `scale` and convert the data.frame to a *dgCMatrix* that can be analyzed with `vsp` R package. However, not standardizing the items does not change the following results much here because there cannot be large outliers in item responses and item variances due to the fixed response format (all items are measured on a Likert scale with 4 labeled categories).\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nitems_mat_z = as.matrix(scale(phonedata_items))\ncolnames(items_mat_z) = colnames(phonedata_items)\nitems_mat_z = as(items_mat_z, \"dgCMatrix\")\n```\n:::\n\n\nThe screeplot suggests a decrease in singular values after the 5th component. This is in line with the theory behind the questionnaire that was constructed to measure the Big Five personality factors.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nscreeplot(vsp(items_mat_z, rank = 50,\n  degree_normalize = FALSE, center = FALSE))\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nNote that each Big Five factor is represented in the questionnaire by 6 lower order personality facets measured by 10 items each. Thus, theory would suggest that extracting 30 components should also be meaningful.\n\nTo keep it simple, we extract only 5 components here.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npca_items_z = vsp(items_mat_z, rank = 5,\n  degree_normalize = FALSE, center = FALSE)\n```\n:::\n\n\nNote that we do set `degree_normalize = FALSE` and `center = FALSE` because we do not analyze binary network data and we have already standardized our item responses.\n\nWe search for **radial streaks** in the estimated component and loading matrices:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_items_z$Z[, 1:5]), cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"Estimated components (with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nWe do not find streaks in the estimated component matrix $\\hat{Z}$.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_items_z$Y[, 1:5]), cex = 0.5, col = alpha(\"red\", alpha = 0.3), \n  main = \"Estimated loadings (with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nHowever, we find noisy streaks in the estimated loading matrix $\\hat{Y}$. This **simple structure** is in line with the construction process of the personality questionnaire, which has the goal that each item measures only a single Big Five factor. Streaks are even more pronounced when extracting 30 components.\n\nFinally, we interpret the components by highlighting the 10 items with the highest absolute loadings on each component.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nn = 10\ntop_vars_items_z = data.frame(\n  Extraversion = names(sort(abs(pca_items_z$Y[, 1]), decreasing = TRUE)[1:n]),\n  Conscientiousness = names(sort(abs(pca_items_z$Y[, 2]), decreasing = TRUE)[1:n]),\n  Agreeableness = names(sort(abs(pca_items_z$Y[, 3]), decreasing = TRUE)[1:n]),\n  EmotionalStability = names(sort(abs(pca_items_z$Y[, 4]), decreasing = TRUE)[1:n]),\n  Openness = names(sort(abs(pca_items_z$Y[, 5]), decreasing = TRUE)[1:n])\n)\nkable(top_vars_items_z)\n```\n\n::: {.cell-output-display}\n\n\n|Extraversion |Conscientiousness |Agreeableness |EmotionalStability |Openness |\n|:------------|:-----------------|:-------------|:------------------|:--------|\n|E1.1         |C6.8              |A6.8          |ES6.10             |O2.6     |\n|E4.3         |C2.5              |O3.3          |ES1.3              |O2.5     |\n|E2.7         |C4.9              |A6.10         |ES2.3              |O6.2     |\n|E2.2         |ES5.6             |A6.2          |ES2.9              |O2.10    |\n|E2.4         |C3.6              |O3.7          |ES2.7              |O5.4     |\n|E2.8         |C5.6              |E1.7          |ES2.1              |O1.6     |\n|E4.5         |C3.1              |A6.6          |ES2.8              |O1.2     |\n|ES4.10       |C2.7              |A6.4          |ES3.7              |O1.9     |\n|E2.6         |C4.5              |A6.5          |ES1.4              |O2.8     |\n|E3.2         |C2.3              |O3.1          |ES2.6              |O2.1     |\n\n\n:::\n:::\n\n\nWith few exceptions, the item labels indicate that the implied Big Five personality factors (*Extraversion*, *Conscientiousness*, *Agreeableness*, *Emotional Stability*, *Openness*) were recovered as expected.\n\n## Mobile Sensing Data\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nphonedata_sensing = readRDS(file = \"datasets/clusterdata.RDS\")\nphonedata_sensing = phonedata_sensing[, c(1:1821)]\n```\n:::\n\n\nThe smartphone sensing data contains 1821 preprocessed variables. Of these variables, 772 contain missing values and not a single person has complete data on all variables. Thus, imputation of missing values seems a necessity when working with these data. We use very simple mean imputation here which is sufficient for the goal of our demonstration.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nphonedata_sensing_imp = phonedata_sensing\nfor(col in colnames(phonedata_sensing_imp)) {\n  phonedata_sensing_imp[which(is.na(phonedata_sensing_imp[[col]])), col] <-\n    mean(phonedata_sensing_imp[[col]], na.rm = TRUE)\n}\n```\n:::\n\n\nHowever, our results are quite similar for more elaborate imputation schemes.\nFor the interested reader, we prepared data imputed with the `miceRanger` package in the [sensitivity analysis document](sensitivity_analysis.qmd).\n\nIf you want to use that data, you have to set `eval: true` or manually run the following chunk in the *.qmd* file.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\nlibrary(miceRanger)\nmice_obj_sensing = readRDS(file = \"mice_obj_sensing.RDS\")\nphonedata_sensing_imp = as.data.frame(completeData(mice_obj_sensing)[[1]])\n```\n:::\n\n\n### Analysis with Standardization\n\nIn contrast to the item response data, there is a huge difference in the standard deviations of the smartphone sensing variables.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nround(quantile(sapply(phonedata_sensing_imp, sd)), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        0%        25%        50%        75%       100% \n      0.02       0.21       2.13      12.81 1723949.43 \n```\n\n\n:::\n:::\n\n\nThus, it is important to standardize the variables before further analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsensing_mat_imp_z = as.matrix(scale(phonedata_sensing_imp))\ncolnames(sensing_mat_imp_z) = colnames(phonedata_sensing_imp)\nsensing_mat_imp_z = as(sensing_mat_imp_z, \"dgCMatrix\")\nscreeplot(vsp(sensing_mat_imp_z, rank = 50, \n  degree_normalize = FALSE, center = TRUE))\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe screeplot does not show a clear gap or elbow for the smartphone sensing data. To keep it simple, we extract only 5 components here, but higher numbers also provide meaningful insights.\n\nAgain, we do not use degree normalization but we set `center = TRUE` despite standardizing the columns because row means also differ to some extent.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npca_sensing_imp_z = vsp(sensing_mat_imp_z, rank = 5, \n  degree_normalize = FALSE, center = TRUE)\n```\n:::\n\n\nWe search for **radial streaks** in the estimated component and loading matrices:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_sensing_imp_z$Z[, 1:5]), cex = 0.3, col = alpha(\"red\", alpha = 0.1), \n  main = \"Estimated components (with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe do not find a clear indication of streaks in the estimated component matrix $\\hat{Z}$.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_sensing_imp_z$Y[, 1:5]), cex = 0.3, col = alpha(\"red\", alpha = 0.1), \n  main = \"Estimated loadings (with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nHowever, we find streaks in the estimated loading matrix $\\hat{Y}$. In contrast to the items of the personality questionnaire that have been constructed with simple structure in mind, no simple structure was implied when constructing the smartphone sensing variables. Nonetheless, the streaks would suggest that the smartphone sensing variables can be meaningfully clustered in this dataset.\n\nFor interpretation, we again highlight the 10 variables with the highest absolute loadings on each component.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nn = 10\ntop_vars_z = data.frame(\n  Apps_Usage = names(sort(abs(pca_sensing_imp_z$Y[, 1]), decreasing = TRUE)[1:n]),\n  Calls = names(sort(abs(pca_sensing_imp_z$Y[, 2]), decreasing = TRUE)[1:n]),\n  Music_Songs = names(sort(abs(pca_sensing_imp_z$Y[, 3]), decreasing = TRUE)[1:n]),\n  Music_Audio_Features = names(sort(abs(pca_sensing_imp_z$Y[, 4]), decreasing = TRUE)[1:n]),\n  Terrain = names(sort(abs(pca_sensing_imp_z$Y[, 5]), decreasing = TRUE)[1:n])\n)\nkable(top_vars_z)\n```\n\n::: {.cell-output-display}\n\n\n|Apps_Usage                           |Calls                         |Music_Songs                  |Music_Audio_Features            |Terrain                                      |\n|:------------------------------------|:-----------------------------|:----------------------------|:-------------------------------|:--------------------------------------------|\n|daily_mean_num_unique_apps_week      |daily_mean_num_cont_call      |daily_mean_num_song          |mean_music_loudness             |daily_mean_neg_elev_change                   |\n|daily_mean_num_unique_apps           |daily_mean_num_cont           |daily_mean_duration_music    |mean_music_loudness_weekday     |daily_mean_elev_change                       |\n|daily_mean_num_unique_apps_weekend   |daily_mean_num_cont_week      |daily_max_num_uniq_song      |sd_music_loudness               |daily_mean_pos_elev_change                   |\n|daily_mean_num_unique_Camera         |daily_mean_num_cont_call_out  |daily_mean_num_song_weekdays |mean_music_energy               |daily_mean_elev_change_weekdays              |\n|daily_mean_num_unique_Camera_week    |daily_sd_num_call_in          |daily_mean_num_uniq_song     |mean_music_loudness_weekend     |daily_mean_elev_change_weekend               |\n|daily_mean_num_unique_Camera_weekend |IVI_calls                     |num_uniq_songs               |mean_music_acousticness         |daily_sd_elev_change                         |\n|daily_mean_sum_events_daytime        |daily_mean_num_cont_call_miss |daily_sd_num_song            |mean_music_energy_weekday       |daily_mean_num_.com.sonyericsson.home        |\n|daily_mean_sum_events_night          |daily_mean_num_cont_weekend   |num_songs                    |mean_music_acousticness_weekday |daily_mean_num_.com.sec.android.app.launcher |\n|daily_mean_num_unique_Gallery        |daily_mean_num_call_out       |daily_mean_num_uniq_alb      |sd_music_acousticness           |daily_mean_num_.com.sec.android.gallery3d    |\n|daily_mean_num_unique_Gallery_week   |daily_mean_num_cont_call_in   |daily_sd_duration_music      |mean_music_energy_weekend       |daily_mean_num_.com.sonyericsson.album       |\n\n\n:::\n:::\n\n\nTo summarize, with careful preprocessing and appropriate data standardization, PCA+VR seems to meaningfully cluster the smartphone sensing variables, as indicated by radial streaks in the estimated loading matrix $\\hat{Y}$. However, we did not find streaks in the estimated component matrix $\\hat{Z}$ so we cannot necessarily have high confidence that PCA+VR was able to estimate well identified person scores on these components.\n\nThe following cautionary example showcases what can happen when the smartphone sensing data is not preprocessed with enough care.\n\n### A Cautionary example: Analysis without Standardization\n\nTo simulate mindless data analysis, we do not standardize the smartphone sensing variables and use the default `degree_normalize = TRUE` in the `vsp` call, although this should not be a meaningful setting because we do not analyze binary network data here.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsensing_mat_imp = as.matrix(phonedata_sensing_imp)\ncolnames(sensing_mat_imp) = colnames(phonedata_sensing_imp)\nsensing_mat_imp = as(sensing_mat_imp, \"dgCMatrix\")\nscreeplot(vsp(sensing_mat_imp, rank = 50,\n  degree_normalize = TRUE, center = TRUE))\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nWith these settings, the screeplot shows substantial gaps (in contrast to the previous analysis with standardization). To keep it simple, we decided to extract 5 components here, but the main insights from this exercise do not seem to depend on this number.\n\nWhen searching for **radial streaks** in the estimated component and loading matrices, we notice interesting changes compared to the analysis with standardized variables\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npca_sensing_imp = vsp(sensing_mat_imp, rank = 5,\n  degree_normalize = TRUE, center = TRUE)\npairs(as.matrix(pca_sensing_imp$Z[, 1:5]), cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"Estimated components (no standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nWith these settings, we *do* find beautiful streaks in the estimated component matrix $\\hat{Z}$.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_sensing_imp$Y[, 1:5]), cex = 0.5, col = alpha(\"red\", alpha = 0.4), \n  main = \"Estimated loadings (no standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nIn contrast, streaks in the estimated loading matrix $\\hat{Y}$ are very extreme. To a careful analyst, this might perhaps raise some alarms that something might be wrong here...\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nn = 20\ntop_vars = data.frame(\n  GPS1 = names(sort(abs(pca_sensing_imp$Y[, 1]), decreasing = TRUE)[1:n]),\n  GPS2 = names(sort(abs(pca_sensing_imp$Y[, 2]), decreasing = TRUE)[1:n]),\n  GPS3 = names(sort(abs(pca_sensing_imp$Y[, 3]), decreasing = TRUE)[1:n]),\n  GPS4 = names(sort(abs(pca_sensing_imp$Y[, 4]), decreasing = TRUE)[1:n]),\n  GPS5 = names(sort(abs(pca_sensing_imp$Y[, 5]), decreasing = TRUE)[1:n])\n)\nred_vars = unique(unlist(top_vars))\nkable(top_vars)\n```\n\n::: {.cell-output-display}\n\n\n|GPS1                               |GPS2                               |GPS3                               |GPS4                               |GPS5                               |\n|:----------------------------------|:----------------------------------|:----------------------------------|:----------------------------------|:----------------------------------|\n|maxDistance                        |huberM_time_spent_home             |huberM_distance_covered_weekend    |huberM_daily_max_dist_home         |huberM_time_spent_home_weekend     |\n|max_distance_home                  |huberM_time_spent_home_weekday     |huberM_distance_covered_daily      |huberM_daily_max_dist_home_weekday |durationHome                       |\n|rog                                |durationHome                       |huberM_distance_covered_weekday    |huberM_daily_max_dist_home_weekend |huberM_time_spent_home_weekday     |\n|SDD                                |max_distance_home                  |huberM_max_dist_two_points_weekend |durationHome                       |huberM_daily_max_dist_home_weekend |\n|SDD_daytime                        |maxDistance                        |huberM_max_dist_two_points_daily   |SDD_nighttime                      |SDD_weekend                        |\n|SDD_weekend                        |huberM_time_spent_home_weekend     |huberM_max_dist_two_points_weekday |max_distance_home                  |SDD_sat                            |\n|SDD_sat                            |huberM_daily_max_dist_home_weekend |huberM_rog_weekends                |maxDistance                        |SDD_nighttime                      |\n|SDD_weekday                        |huberM_daily_time_spent_home       |huberM_rog_daily                   |SDD                                |SDD                                |\n|SDD_nighttime                      |huberM_daily_max_dist_home         |huberM_rog_weekdays                |rog                                |mean_dur_wakeLeaveHome_weekend     |\n|huberM_daily_max_dist_home_weekday |rog                                |Qn_rog_weekends                    |SDD_sat                            |huberM_distance_covered_daily      |\n|huberM_time_spent_home_weekday     |huberM_distance_covered_daily      |huberM_rog_nightly                 |huberM_max_dist_two_points_weekend |mean_time_firstLeave               |\n|huberM_daily_max_dist_home_weekend |huberM_daily_max_dist_home_weekday |max_distance_home                  |SDD_daytime                        |mean_time_LeaveHome_weekday        |\n|huberM_time_spent_home             |SDD_nighttime                      |huberM_daily_max_dist_home_weekend |Qn_rog_weekends                    |huberM_rog_weekends                |\n|huberM_daily_max_dist_home         |huberM_distance_covered_weekday    |SDD                                |huberM_time_spent_home_weekend     |SDD_daytime                        |\n|huberM_distance_covered_weekend    |huberM_distance_covered_weekend    |SDD_daytime                        |huberM_daily_time_spent_home       |huberM_distance_covered_weekday    |\n|huberM_distance_covered_weekday    |huberM_max_dist_two_points_weekend |SDD_weekday                        |huberM_distance_covered_weekday    |mean_dur_wakeLeave                 |\n|huberM_distance_covered_daily      |SDD_weekend                        |SDD_nighttime                      |huberM_distance_covered_daily      |mean_time_lastHome                 |\n|huberM_max_dist_two_points_daily   |huberM_rog_weekends                |SDD_weekend                        |huberM_rog_weekends                |huberM_rog_nightly                 |\n|huberM_max_dist_two_points_weekend |mean_time_lastHome                 |maxDistance                        |huberM_max_dist_two_points_daily   |mean_time_LeaveHome                |\n|huberM_max_dist_two_points_weekday |daily_sd_elev_change               |SDD_sat                            |huberM_max_dist_two_points_weekday |mean_time_lastHome_weekend         |\n\n\n:::\n:::\n\n\nIndeed, when looking at the top variables with the highest absolute loadings on each component, they do **not** seem to have a simple structure and are hard to interpret.\n\nIn fact, the top 20 variables loading on all components include only 36 unique variables.\n\nMost of these variables seem to be based on GPS data in some way.\n\nAll of these variables have extremely high standard deviations.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsapply(phonedata_sensing_imp[, red_vars], sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       maxDistance                  max_distance_home \n                      1723949.4317                       1658119.0296 \n                               rog                                SDD \n                       593713.5051                        104176.6763 \n                       SDD_daytime                        SDD_weekend \n                       110929.5007                        127175.3902 \n                           SDD_sat                        SDD_weekday \n                       118107.2267                         96185.8329 \n                     SDD_nighttime huberM_daily_max_dist_home_weekday \n                        89259.8191                        386481.1616 \n    huberM_time_spent_home_weekday huberM_daily_max_dist_home_weekend \n                       396556.4282                        597855.8383 \n            huberM_time_spent_home         huberM_daily_max_dist_home \n                       362331.9954                        395986.1722 \n   huberM_distance_covered_weekend    huberM_distance_covered_weekday \n                       273597.0960                        236849.2267 \n     huberM_distance_covered_daily   huberM_max_dist_two_points_daily \n                       228491.3102                         36548.9043 \nhuberM_max_dist_two_points_weekend huberM_max_dist_two_points_weekday \n                        51418.1852                         37995.9337 \n                      durationHome     huberM_time_spent_home_weekend \n                       630997.9841                        356598.2761 \n      huberM_daily_time_spent_home                huberM_rog_weekends \n                        23839.3676                         19736.6958 \n                mean_time_lastHome               daily_sd_elev_change \n                        13992.7979                           652.7301 \n                  huberM_rog_daily                huberM_rog_weekdays \n                        13893.6231                         15196.8947 \n                   Qn_rog_weekends                 huberM_rog_nightly \n                        21541.5438                         15109.0978 \n    mean_dur_wakeLeaveHome_weekend               mean_time_firstLeave \n                        13712.9354                         12298.1192 \n       mean_time_LeaveHome_weekday                 mean_dur_wakeLeave \n                        12196.0186                         12383.4894 \n               mean_time_LeaveHome         mean_time_lastHome_weekend \n                        12203.8207                         14425.9489 \n```\n\n\n:::\n:::\n\n\nIn addition, all of these variables contain missing values in the original dataset and the number of missings is quite high for some of them.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsapply(phonedata_sensing[, red_vars], function(x) sum(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       maxDistance                  max_distance_home \n                                58                                 69 \n                               rog                                SDD \n                                63                                 60 \n                       SDD_daytime                        SDD_weekend \n                                66                                107 \n                           SDD_sat                        SDD_weekday \n                               114                                 82 \n                     SDD_nighttime huberM_daily_max_dist_home_weekday \n                               110                                 91 \n    huberM_time_spent_home_weekday huberM_daily_max_dist_home_weekend \n                                97                                204 \n            huberM_time_spent_home         huberM_daily_max_dist_home \n                                69                                 69 \n   huberM_distance_covered_weekend    huberM_distance_covered_weekday \n                               120                                 83 \n     huberM_distance_covered_daily   huberM_max_dist_two_points_daily \n                                67                                 60 \nhuberM_max_dist_two_points_weekend huberM_max_dist_two_points_weekday \n                               110                                 77 \n                      durationHome     huberM_time_spent_home_weekend \n                                69                                189 \n      huberM_daily_time_spent_home                huberM_rog_weekends \n                                69                                133 \n                mean_time_lastHome               daily_sd_elev_change \n                                70                                  5 \n                  huberM_rog_daily                huberM_rog_weekdays \n                                74                                 90 \n                   Qn_rog_weekends                 huberM_rog_nightly \n                               133                                132 \n    mean_dur_wakeLeaveHome_weekend               mean_time_firstLeave \n                                 5                                 60 \n       mean_time_LeaveHome_weekday                 mean_dur_wakeLeave \n                               123                                  5 \n               mean_time_LeaveHome         mean_time_lastHome_weekend \n                                93                                230 \n```\n\n\n:::\n:::\n\n\nOur suspicion is that the radial streaks in the estimated component matrix $\\hat{Z}$ might be a result of these GPS variables, which dominate the solution from PCA+VR without standardization but are hidden behind the remaining variables when standardization is used.\n\nTo confirm some of these suspicions, we repeat PCA+VR on only these 36 variables, but now use standardization again. This results in 2 strong components with pronounced but odd-looking and not perfectly aligned streaks in both $\\hat{Z}$ and $\\hat{Y}$.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsensing_mat_imp_z_red = as.matrix(scale(phonedata_sensing_imp[, red_vars]))\ncolnames(sensing_mat_imp_z_red) = colnames(phonedata_sensing_imp[, red_vars])\nsensing_mat_imp_z_red = as(sensing_mat_imp_z_red, \"dgCMatrix\")\nscreeplot(vsp(sensing_mat_imp_z_red, rank = 20,\n  degree_normalize = FALSE, center = TRUE))\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npca_sensing_imp_z_red = vsp(sensing_mat_imp_z_red, rank = 2, \n  degree_normalize = FALSE, center = TRUE)\npairs(as.matrix(pca_sensing_imp_z_red$Z[, 1:2]), cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"Estimated components (reduced itemset with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_sensing_imp_z_red$Y[, 1:2]), cex = 0.5, col = alpha(\"red\", alpha = 0.6), \n  main = \"Estimated loadings (reduced itemset with standardization)\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nn = 10\ntop_vars = data.frame(\n  GPS1 = names(sort(abs(pca_sensing_imp_z_red$Y[, 1]), decreasing = TRUE)[1:n]),\n  GPS2 = names(sort(abs(pca_sensing_imp_z_red$Y[, 2]), decreasing = TRUE)[1:n])\n)\nkable(top_vars)\n```\n\n::: {.cell-output-display}\n\n\n|GPS1                               |GPS2                               |\n|:----------------------------------|:----------------------------------|\n|rog                                |mean_time_LeaveHome                |\n|maxDistance                        |mean_time_LeaveHome_weekday        |\n|max_distance_home                  |mean_time_firstLeave               |\n|SDD                                |mean_dur_wakeLeave                 |\n|SDD_daytime                        |huberM_max_dist_two_points_daily   |\n|SDD_weekend                        |huberM_rog_daily                   |\n|SDD_sat                            |huberM_max_dist_two_points_weekday |\n|SDD_weekday                        |huberM_distance_covered_daily      |\n|huberM_rog_daily                   |huberM_time_spent_home_weekday     |\n|huberM_max_dist_two_points_weekday |huberM_time_spent_home             |\n\n\n:::\n:::\n\n\n# Simulation: Correlated Factors\n\nAnother important aspect of psychological applications of PCA+VR are correlated factors (e.g., the personality dimensions conscientiousness and neuroticism are thought to correlate around $-0.4$; @vanderlinden2010general), thus oblique rotations are often argued for. Interestingly, R&Z show as a side result that the results of PCA+VR can be used to also estimate correlated factors in situations which are relevant for psychological measurement models.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\nlibrary(vsp)\nlibrary(Matrix)\nlibrary(scales)\nlibrary(mvtnorm)\n```\n:::\n\n\nHere we demonstrate that $\\hat{Z}\\hat{B}$ (up to a change of units) estimates correlated factors simulated from a leptokurtic distribution:\n\n1.  Simulate correlated factor scores from a multivariate leptokurtic distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\nset.seed(3)\n\nn = 10000\nrho = 0.7\n# adapted from https://github.com/RoheLab/vsp-paper/blob/master/scripts/makeFigure1.R\nZ_star = scale(matrix(sample(c(-1,1), 2 * n, T) * \n    rexp(n * 2, rate = 2) ^ 1.3, ncol = 2))\ncor_mat = matrix(c(1, rho, rho, 1), ncol = 2)\nZ = Z_star %*% chol(cor_mat)\n```\n:::\n\n\nWe first simulate two-dimensional uncorrelated standardized scores from a leptokurtic distribution ($Z^*$). Correlated scores ($Z$) are then constructed by multiplying the uncorrelated scores with the Cholesky factor of a correlation matrix with the desired correlation ($\\rho = 0.7$).\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(Z, cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"True correlated factors\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nWhen plotting the simulated component scores in the $Z$ matrix, we see non-orthogonal streaks (i.e. oblique components).\n\n2.  Simulate item response data.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nk = 2\nvpf = 20\nd = vpf*k\n\npf_low = 0.8\npf_upper = 0.95\nsf_low = 0\nsf_upper = 0\n\nloadings = function(k, d, vpf, pf_low, pf_upper, sf_low, sf_upper){\n  x = runif(d, pf_low, pf_upper)\n  y = runif(d*(k-1) , sf_low, sf_upper)\n  i = 1:(d)\n  j = rep(1:k, each = vpf)\n  L = matrix(NA, d, k)\n  L[cbind(i, j)] = x\n  L[is.na(L)] = y\n  L\n}\n\nY = loadings(k, d, vpf, pf_low, pf_upper, sf_low, sf_upper)\nA =  Z %*% t(Y) + rnorm(n * d, sd = 0.1)\n```\n:::\n\n\nWe create a loading matrix $Y$ with simple structure and simulate the data matrix $A$ with $ZY^T$ and add some normally distributed noise.\n\n3.  Perform PCA + Varimax\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npca_sim = vsp(A, rank = 2, degree_normalize = FALSE)\n```\n:::\n\n\n4.  Estimate uncorrelated component scores $Z$\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npairs(as.matrix(pca_sim$Z[, 1:2]), cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"Estimated uncorrelated factors\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nWhen plotting the $\\hat{Z}$ matrix returned from PCA+VR, we see orthogonal streaks similar to $Z^*$.\n\n5.  Estimate correlated component scores $Z$\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nZB_hat = as.matrix(pca_sim$Z) %*% as.matrix(pca_sim$B)\npairs(ZB_hat, cex = 0.5, col = alpha(\"red\", alpha = 0.2), \n  main = \"Estimated correlated factors\")\n```\n\n::: {.cell-output-display}\n![](electronic_supplemental_material_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nHowever, the matrix $\\hat{Z}\\hat{B}$ contains correlated components similar to $Z$.\n\n6.  Estimate correlation between components\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncor(ZB_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 1.0000000 0.7033317\n[2,] 0.7033317 1.0000000\n```\n\n\n:::\n:::\n\n\nWe can verify that the correlation of the scores in $\\hat{Z}\\hat{B}$ are close to the true correlation in $Z$ ($\\rho = 0.7$).\n\nOur simulation seems to demonstrate the results from sections **7.1** and **7.2** in R&Z, which state that if scores in $Z$ are correlated; scores in $Y$ are centered, independent, and leptokurtic; and the true $B$ is proportional to the identity matrix, then the $\\hat{B}$ matrix returned from PCA+VR estimates the Cholesky factor of the covariance matrix $Z^TZ$ (up to a change of unit). Note that because our scores in $Z$ were scaled, $Z^TZ$ is equal to the correlation matrix in our demonstration.\n\n## Open Questions\n\nSurprisingly, the exact scores in $Z$ (in the same unit) seem to be estimated by $\\hat{Z}\\hat{B}\\cdot d^{1/8}$.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nnrows = 10\ncompare_scores = data.frame(\n  z1 = Z[1:nrows, 1],\n  z1_hat = ZB_hat[1:nrows, 1] * d^(1/8),\n  z2 = Z[1:nrows, 2],\n  z2_hat = ZB_hat[1:nrows, 2] * d^(1/8),\nrow.names = NULL)\nkable(compare_scores)\n```\n\n::: {.cell-output-display}\n\n\n|         z1|     z1_hat|         z2|     z2_hat|\n|----------:|----------:|----------:|----------:|\n| -0.8175379| -0.8258829|  0.3337107|  0.3052195|\n|  0.1451648|  0.1404835|  0.9071543|  0.9425134|\n|  0.3726275|  0.3342478| -0.0673917| -0.0741674|\n| -0.0312845| -0.0496686|  1.0465835|  1.0630476|\n|  0.0533857|  0.0278354| -0.0289375| -0.0004230|\n|  2.7693088|  2.7368688|  2.0474298|  2.0732120|\n|  0.6403584|  0.6849868|  0.3958977|  0.3967702|\n| -0.5940332| -0.5576306| -0.1732053| -0.1453989|\n| -0.2614659| -0.2740095| -0.7323451| -0.7558590|\n|  0.6697399|  0.6585350|  0.4020305|  0.4119104|\n\n\n:::\n:::\n\n\nUnfortunately, we were not able not determine why or whether this might be just a coincidence here. To conclude, we agree with the following comment in R&Z [@rohe2023vintage] and are looking forward to further research in this direction:\n\n> Taken together, this all suggests that the B matrix provides a path to understanding “correlation among the factors.” Understanding this phenomenon is an active area of research in our lab.\n\n# References\n\n::: {#refs}\n:::\n",
    "supporting": [
      "electronic_supplemental_material_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}